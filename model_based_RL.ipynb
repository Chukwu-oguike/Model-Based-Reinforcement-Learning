{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The project  consists of three classes: the GridWorld; the GridRules and the Agent.\n",
        "\n",
        "\n",
        "The Gridworld class has two variables: two different tracks defined as 2D character numpy arrays. The two tracks correspond to the two configurations of the maze in the problem\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The GridRules class defines the rules that govern how the agents moves in the maze. It takes two arguments: and instance of the GridWorld class; and an integer specifying the identity of the maze initially used in the GridWorld class.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Agent class defines the structure of the agent. It has two important functions: “run_episode_DaynaQ_ex”  which implements the Alternate Method referenced in the problem set and “run_episode_DaynaQpve” which implements the DynaQ+ method.  This functions return the optimal sequence of actions after each episode. This class takes three arguments: GridRules class; the value for epsilon; the value of the learning rate; the discount value; the initial values for the state-actions pairs, the number of planning steps, and the value of the constant for the bonus reward. The function “show_agent_sequence” displays the path traversed by the agent in the maze.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "The notebook’s cells should be run in sequential order and the parameters such as epsilon; number of episodes, learning rate, planning steps, etc can be adjusted accordingly. The output of the entire program is a cmap of the paths taken by the agent and plot of the cumulative reward vs steps and the steps per episode vs the episodes\n"
      ],
      "metadata": {
        "id": "nIAow1yXsGoq"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Urdm_7dOfYY"
      },
      "source": [
        "# Data structures packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import math\n",
        "\n",
        "\n",
        "# Plotting Packages\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.ticker as mtick"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Xc9ueJcOgw4"
      },
      "source": [
        "class gridWorld:\n",
        "    maze_1 = np.array([\n",
        "\n",
        "                ['t','t','t','t','t','t','t','t','G'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','B','B','B','B','B','B','B','B'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','t','t','S','t','t','t','t','t'],\n",
        "\n",
        "              ])\n",
        "\n",
        "    maze_2 = np.array([\n",
        "\n",
        "                ['t','t','t','t','t','t','t','t','G'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','B','B','B','B','B','B','B','t'],\n",
        "                ['t','t','t','t','t','t','t','t','t'],\n",
        "                ['t','t','t','S','t','t','t','t','t'],\n",
        "\n",
        "              ])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5QpropHD0WK"
      },
      "source": [
        "class gridRules:\n",
        "\n",
        "    # Constants\n",
        "    VALID_MOVE_REWARD = 0\n",
        "    INVALID_MOVE_REWARD = 0\n",
        "    GOAL_REWARD = 5\n",
        "\n",
        "    # description of cell values\n",
        "    OPEN_VALUE = 't'\n",
        "    BOUNDS_VALUE = 'B'\n",
        "    START_VALUE = 'S'\n",
        "    GOAL_VALUE = 'G'\n",
        "    AGENT_VALUE = 'A'\n",
        "\n",
        "    def __init__(self, maze, maze_num):\n",
        "\n",
        "        #initialize maze\n",
        "        self.maze = maze\n",
        "        self.finished = False\n",
        "        self.RAND_POS_CHANGE_PROBABILITY = 0.5 # Experimental scenario (randomly void an action taken by the agent)\n",
        "\n",
        "        if maze_num == 1:\n",
        "            self.maze_type = self.maze.maze_1\n",
        "        elif track_num == 2:\n",
        "            self.maze_type = self.maze.maze_2\n",
        "\n",
        "        self.position = self.get_start_position()\n",
        "\n",
        "\n",
        "    # get the location of the character 'S' in the maze\n",
        "    def get_start_position(self):\n",
        "\n",
        "        x_coordinates, y_coordinates = np.where(self.maze_type == self.START_VALUE)\n",
        "\n",
        "        return (x_coordinates[0], y_coordinates[0])\n",
        "\n",
        "\n",
        "    # Move agent\n",
        "    def update_position(self, action):\n",
        "\n",
        "        self.position = (self.position[0] + action[0], self.position[1] + action[1])\n",
        "\n",
        "    # ensure agent is not out-of-bounds; return true if so, else false\n",
        "    def check_out_of_bounds(self):\n",
        "\n",
        "        boundry = self.position[0] < 0 or self.position[0] >= self.maze_type.shape[0] or \\\n",
        "        self.position[1] < 0 or self.position[1] >= self.maze_type.shape[1]\n",
        "\n",
        "        if boundry:\n",
        "            return True\n",
        "        elif self.maze_type[self.position] == self.BOUNDS_VALUE:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "\n",
        "    # Reset agent's position at the end of every episode\n",
        "    def reset_agent_state(self):\n",
        "\n",
        "        self.position = self.get_start_position()\n",
        "        self.finished = False\n",
        "\n",
        "    # Return the state of the agent\n",
        "    def get_agent_state(self):\n",
        "\n",
        "        return (self.position[0], self.position[1])\n",
        "\n",
        "    # Check if agent has reached one of the end locations Return true if so, else return False\n",
        "    def check_finish(self, last_state):\n",
        "\n",
        "        if self.check_out_of_bounds():\n",
        "            self.position = last_state\n",
        "\n",
        "        if self.maze_type[self.position] == self.GOAL_VALUE:\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "\n",
        "    # change the configuration of the maze\n",
        "    def change_maze(self,maze_number):\n",
        "\n",
        "        if maze_number == 1:\n",
        "            self.maze_type = self.maze.maze_1\n",
        "        elif maze_number == 2:\n",
        "            self.maze_type = self.maze.maze_2\n",
        "\n",
        "\n",
        "    # Move Agent\n",
        "    def move_agent(self, x_move, y_move):\n",
        "\n",
        "        assert not self.finished\n",
        "\n",
        "        last_position = self.position\n",
        "\n",
        "        # Comment out this line to run the experimental scenario\n",
        "        self.update_position((x_move, y_move))\n",
        "\n",
        "\n",
        "        #Uncomment this if-else section of code to run the experimental scenario\n",
        "        # if np.random.uniform(0, 1) < self.RAND_POS_CHANGE_PROBABILITY:\n",
        "        #     self.update_position((0, 0))\n",
        "\n",
        "        # else:\n",
        "        #     self.update_position((x_move, y_move))\n",
        "\n",
        "        # Check if finished\n",
        "        if self.check_finish(last_position):\n",
        "            self.finished = True\n",
        "            print(\"Agent has found goal!\")\n",
        "            return self.GOAL_REWARD\n",
        "\n",
        "        # Check for invalid position\n",
        "        invalid_position = False\n",
        "\n",
        "        if self.check_out_of_bounds():\n",
        "            invalid_position = True\n",
        "            self.position = last_position\n",
        "\n",
        "        # Check if finished again\n",
        "        if self.check_finish(last_position):\n",
        "            self.finished = True\n",
        "\n",
        "            if invalid_position:\n",
        "                self.position = last_position\n",
        "                return self.INVALID_MOVE_REWARD\n",
        "            else:\n",
        "                return self.VALID_MOVE_REWARD\n",
        "\n",
        "        if invalid_position:\n",
        "            self.position = last_position\n",
        "            return self.INVALID_MOVE_REWARD\n",
        "        else:\n",
        "            return self.VALID_MOVE_REWARD\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTsSX45FDC0s"
      },
      "source": [
        "class Agent:\n",
        "\n",
        "    ACTIONS_DIM = 4\n",
        "    ACTIONS = [[0, 1], [1, 0], [-1, 0], [0, -1]]\n",
        "\n",
        "    # Initialize agent\n",
        "    def __init__(self, rules, epsilon, alpha, discount, init, n, k):\n",
        "        self.rules = rules\n",
        "        self.epsilon = epsilon\n",
        "        self.init = init\n",
        "        self.alpha = alpha\n",
        "        self.discount_factor = discount\n",
        "        self.k = k\n",
        "        self.n = n\n",
        "\n",
        "        self.state_action_values = None\n",
        "        self.state_action_time_elasped = None\n",
        "        # self.state_action_bonus = None\n",
        "        self.state_action_counts = None\n",
        "        self.model = None\n",
        "        self.policy = None\n",
        "        self.no_steps = 0\n",
        "        self.tried_state_actions = []\n",
        "        self.cumulative_rewards = []\n",
        "        self.cum_reward = 0\n",
        "        self.reset()\n",
        "\n",
        "\n",
        "    # Run episode for traditional DynaQ+\n",
        "    def run_episode_DaynaQpve(self):\n",
        "\n",
        "        sequence = [] #save state-action sequence\n",
        "\n",
        "        while not self.rules.finished:\n",
        "\n",
        "            state = self.rules.get_agent_state()\n",
        "\n",
        "            if self.no_steps == 1000:\n",
        "\n",
        "                self.rules.change_maze(2)\n",
        "\n",
        "            self.no_steps += 1\n",
        "\n",
        "            self.update_policy()\n",
        "\n",
        "            action = self.epsilon_explore(self.policy[state])\n",
        "\n",
        "            reward = self.rules.move_agent(*self.action_to_move(action))\n",
        "\n",
        "            sequence.append((state, action, reward))\n",
        "\n",
        "            self.cum_reward = self.cum_reward + reward\n",
        "\n",
        "            self.cumulative_rewards.append(self.cum_reward)    # store cumulative reward\n",
        "\n",
        "            next_state = self.rules.get_agent_state() # save the next state resulting from a state action pair\n",
        "\n",
        "            state_action = state + (action,)\n",
        "\n",
        "\n",
        "            #save actions that have been tried for model learning\n",
        "            if state_action not in self.tried_state_actions:\n",
        "                self.tried_state_actions.append(state_action)\n",
        "\n",
        "            # update state-action values using DynaQ\n",
        "            self.state_action_values[state_action] = self.state_action_values[state_action] + \\\n",
        "            self.alpha * (reward + (self.discount_factor*self.max_state_action(state)) + self.state_action_values[state_action])\n",
        "\n",
        "            #calculate the number of steps that have elapsed since the action was last tried\n",
        "            time_past = self.no_steps - self.state_action_time_elasped[state_action]\n",
        "\n",
        "            # register this state-action pair as recently tried\n",
        "            self.state_action_time_elasped[state_action] = self.no_steps\n",
        "\n",
        "            # calculate model's reward according to DynaQ+\n",
        "            model_reward = reward + self.k*math.sqrt(time_past)\n",
        "\n",
        "            # save this Reward and proceeding state in the model\n",
        "            self.model[state_action] = (model_reward,) + next_state + (action,)\n",
        "\n",
        "            for i in range(0, self.n):\n",
        "\n",
        "                # randomly select a state-action pair from the list of tried state-action pairs\n",
        "                init_s1, init_s2, init_A = self.rand_select_state_action()\n",
        "\n",
        "                # get the model's reward and next state values for the selected state-action pair\n",
        "                R,S1,S2,A = self.model[(init_s1, init_s2, init_A)]\n",
        "\n",
        "                # indirect learning according to DynaQ\n",
        "                self.state_action_values[(init_s1,init_s2,init_A)] = self.state_action_values[(init_s1,init_s2,init_A)] + \\\n",
        "                self.alpha * (R + (self.discount_factor*self.max_state_action_ex((S1,S2,A))) - self.state_action_values[(init_s1,init_s2,init_A)])\n",
        "\n",
        "        return sequence\n",
        "\n",
        "\n",
        "    def run_episode_DaynaQ_ex(self):\n",
        "\n",
        "        sequence = [] #save state-action sequence\n",
        "\n",
        "        while not self.rules.finished:\n",
        "\n",
        "            state = self.rules.get_agent_state()\n",
        "\n",
        "            if self.no_steps == 1000:\n",
        "\n",
        "                self.rules.change_maze(2)\n",
        "\n",
        "\n",
        "            self.no_steps += 1\n",
        "\n",
        "            self.update_policy_ex()\n",
        "\n",
        "            action = self.epsilon_explore(self.policy[state])\n",
        "\n",
        "            reward = self.rules.move_agent(*self.action_to_move(action))\n",
        "\n",
        "            self.cum_reward = self.cum_reward + reward\n",
        "\n",
        "            self.cumulative_rewards.append(self.cum_reward)\n",
        "\n",
        "            sequence.append((state, action, reward))\n",
        "\n",
        "            next_state = self.rules.get_agent_state()\n",
        "\n",
        "            state_action = state + (action,)\n",
        "\n",
        "            # save actions that have been tried for model learning\n",
        "            if state_action not in self.tried_state_actions:\n",
        "                self.tried_state_actions.append(state_action)\n",
        "\n",
        "            # update state-action values using DynaQ\n",
        "            self.state_action_values[state_action] = self.state_action_values[state_action] + \\\n",
        "            self.alpha * (reward + (self.discount_factor*self.max_state_action_ex(next_state)) + self.state_action_values[state_action])\n",
        "\n",
        "            # register this state-action pair as recently tried\n",
        "            self.state_action_time_elasped[state_action] = self.no_steps\n",
        "\n",
        "            # save this Reward and proceeding state in the model\n",
        "            self.model[state_action] = (reward,) + next_state + (action,)\n",
        "\n",
        "            for i in range(0, self.n):\n",
        "\n",
        "                # randomly select a state-action pair from the list of tried state-action pairs\n",
        "                init_s1, init_s2, init_A = self.rand_select_state_action()\n",
        "\n",
        "                # get the model's reward and next state values for the selected state-action pair\n",
        "                R,S1,S2,A = self.model[(init_s1, init_s2, init_A)]\n",
        "\n",
        "                # indirect learning according to DynaQ\n",
        "                self.state_action_values[(init_s1,init_s2,init_A)] = self.state_action_values[(init_s1,init_s2,init_A)] + \\\n",
        "                self.alpha * (R + (self.discount_factor*self.max_state_action_ex((S1,S2,A))) - self.state_action_values[(init_s1,init_s2,init_A)])\n",
        "\n",
        "\n",
        "        return sequence\n",
        "\n",
        "    # Create array of zeros for policy, state-action values\n",
        "    def reset(self):\n",
        "\n",
        "        self.state_action_values = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM), dtype=np.float32) - self.init\n",
        "\n",
        "        #self.state_action_counts = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM),dtype=np.int32)\n",
        "\n",
        "        # initialize\n",
        "        #self.state_action_bonus = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM), dtype=np.float32)\n",
        "\n",
        "        # initialize model\n",
        "        self.model = np.empty((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM),dtype=object)\n",
        "\n",
        "        # initialize array to keep track of how recently state-action pairs have been tried\n",
        "        self.state_action_time_elasped = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM),dtype=np.float32)\n",
        "\n",
        "        self.policy = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1]),dtype=np.int32)\n",
        "\n",
        "\n",
        "    # select actions with maximum bonus reward for each state (used in the function implementing the alternate method)\n",
        "    def update_policy_ex(self):\n",
        "\n",
        "        bonus_state_action_reward = self.state_action_values + self.k*np.sqrt(self.no_steps - self.state_action_time_elasped)\n",
        "\n",
        "        self.policy = np.argmax(bonus_state_action_reward, axis=-1)\n",
        "\n",
        "    # select actions with maximum reward for each state\n",
        "    def update_policy(self):\n",
        "\n",
        "        self.policy = np.argmax(self.state_action_values, axis=-1)\n",
        "\n",
        "    # get max state-action value for given state\n",
        "    def max_state_action(self, state):\n",
        "\n",
        "        return max([self.state_action_values[state[0]][state[1]][0], self.state_action_values[state[0]][state[1]][1],\n",
        "                    self.state_action_values[state[0]][state[1]][2], self.state_action_values[state[0]][state[1]][3]])\n",
        "\n",
        "\n",
        "    # get max state-action value for given state for the alternate method\n",
        "    def max_state_action_ex(self, state):\n",
        "\n",
        "        # get the bonus reward plus reward for all states-action pairs\n",
        "        bonus_state_action_reward = self.state_action_values + self.k*np.sqrt(self.no_steps - self.state_action_time_elasped)\n",
        "\n",
        "        # return the action with the highest bonus reward plus reward for the given state\n",
        "        return max([bonus_state_action_reward[state[0]][state[1]][0], bonus_state_action_reward[state[0]][state[1]][1],\n",
        "                    bonus_state_action_reward[state[0]][state[1]][2], bonus_state_action_reward[state[0]][state[1]][3]])\n",
        "\n",
        "    # Selected one of the 4 possible actions\n",
        "    def action_to_move(self, action_index):\n",
        "\n",
        "        return self.ACTIONS[action_index]\n",
        "\n",
        "\n",
        "    # Choose random action with a probability of self.epsilon\n",
        "    def epsilon_explore(self, action):\n",
        "\n",
        "        if np.random.uniform(0, 1) < self.epsilon:\n",
        "            return np.random.randint(0, self.ACTIONS_DIM)\n",
        "        else:\n",
        "            return action\n",
        "\n",
        "    # reset the number of steps at the end of each episode\n",
        "    def reset_no_steps(self):\n",
        "\n",
        "        self.no_steps = 0\n",
        "        self.state_action_time_elasped = np.zeros((self.rules.maze_type.shape[0], self.rules.maze_type.shape[1], self.ACTIONS_DIM),dtype=np.float32)\n",
        "\n",
        "\n",
        "    # Randomly select a state-action pair from the list of tried state-actions\n",
        "    def rand_select_state_action(self):\n",
        "\n",
        "        s_a = np.random.randint(0,len(self.tried_state_actions))\n",
        "\n",
        "        return self.tried_state_actions[s_a]\n",
        "\n",
        "\n",
        "    # Display the actions the agent took in the maze\n",
        "    def show_agent_sequence(self, sequence):\n",
        "\n",
        "        # Convert possible track values to distinct integers for cmap\n",
        "        START_VALUE = ord('S')%7\n",
        "        GOAL_VALUE = ord('G')%7\n",
        "        PATH_VALUE = ord('t')%7\n",
        "        BOUNDS_VALUE = ord('B')%7\n",
        "        AGENT_VALUE = ord('A')%7\n",
        "\n",
        "        maze = self.rules.maze_type.copy()\n",
        "\n",
        "        #\n",
        "        for item in sequence:\n",
        "            state = item[0]\n",
        "            maze[state[0], state[1]] = 'A'\n",
        "\n",
        "        maze = maze.tolist()\n",
        "\n",
        "        # convert track characters to ascii and then to distinct integers\n",
        "        for i in range(0,len(maze)):\n",
        "            for j in range(0, len(maze[0])):\n",
        "                maze[i][j] = ord(maze[i][j])%7\n",
        "\n",
        "        maze = np.array(maze)\n",
        "\n",
        "        im = plt.imshow(maze)\n",
        "\n",
        "        plt.axis(\"off\")\n",
        "\n",
        "        values = np.unique(maze.ravel())\n",
        "        labels = {\n",
        "          START_VALUE: \"Start\",\n",
        "          GOAL_VALUE: \"Finish\",\n",
        "          PATH_VALUE: \"Open Path\",\n",
        "          BOUNDS_VALUE: \"Boundry\",\n",
        "          AGENT_VALUE: \"Agent\"\n",
        "        }\n",
        "        colors = [im.cmap(im.norm(value)) for value in values]\n",
        "        patches = [mpatches.Patch(color=colors[i], label=labels[values[i]]) for i in range(len(values))]\n",
        "        plt.legend(handles=patches, loc=4)\n",
        "\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUyEBez0dsck"
      },
      "source": [
        "# run episodes this cell for Alternate Method\n",
        "\n",
        "episodes = 50\n",
        "\n",
        "grid = gridWorld() # instance of maze used by agent\n",
        "maze = gridRules(grid,1) # instance of class setting the rules for agent\n",
        "solver = Agent(maze, 0.2, 0.2, 0.4, 0, 10, 0.1) # instance of Agent def __init__(self, rules, epsilon, alpha, discount, init, n, k)\n",
        "\n",
        "no_steps = []\n",
        "for i in range(episodes):\n",
        "    s = solver.run_episode_DaynaQ_ex()\n",
        "    no_steps.append(solver.no_steps)\n",
        "    solver.reset_no_steps()\n",
        "    maze.reset_agent_state()\n",
        "\n",
        "\n",
        "\n",
        "solver.show_agent_sequence(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm6BJfMMBmBB"
      },
      "source": [
        "# run episodes and print out sequence of agent actions in cmap (tried discount factor 0.8)\n",
        "\n",
        "episodes = 50\n",
        "\n",
        "grid = gridWorld() # instance of maze used by agent\n",
        "maze = gridRules(grid,1) # instance of class setting the rules for agent\n",
        "solver = Agent(maze, 0.2, 0.2, 0.4, 0, 10, 0.1) # instance of Agent def __init__(self, rules, epsilon, alpha, discount, init, n, k)\n",
        "\n",
        "\n",
        "no_steps = []\n",
        "for i in range(episodes):\n",
        "    s = solver.run_episode_DaynaQpve()\n",
        "    no_steps.append(solver.no_steps)\n",
        "    solver.reset_no_steps()\n",
        "    maze.reset_agent_state()\n",
        "\n",
        "\n",
        "\n",
        "solver.show_agent_sequence(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "gY8EDRis2lYX",
        "outputId": "938427f4-2f0f-46a9-c20e-09d7c8db282b"
      },
      "source": [
        "ep = np.arange(episodes)\n",
        "s_e = np.array(no_steps)/ep\n",
        "\n",
        "plt.plot(ep, s_e)\n",
        "plt.title('Returns vs No of Steps with n = 10')\n",
        "plt.xlabel('Episodes')\n",
        "plt.ylabel('No of Steps')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: divide by zero encountered in true_divide\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'No of Steps')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DzpWITpBmr3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "outputId": "dbcf06f7-ef1f-46ca-fce9-6e217e4dd6c7"
      },
      "source": [
        "stepss = np.cumsum(no_steps)\n",
        "stps = np.arange(stepss[49])\n",
        "cumulative_average_reward = solver.cumulative_rewards / stps\n",
        "plt.scatter(stps, solver.cumulative_rewards)\n",
        "plt.title('Returns vs No of Steps with n = 10, Case 2')\n",
        "plt.xlabel('No of Steps')\n",
        "plt.ylabel('Average Reward')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in true_divide\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Average Reward')"
            ]
          },
          "metadata": {},
          "execution_count": 152
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oyh9jpKePPfS"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}